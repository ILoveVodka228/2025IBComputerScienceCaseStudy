# Previous concepts
These concepts are relevant to get some information for the concepts that we're going to work later. I divided because they are implicit in later concepts so understanding these are helpful for the next ones. 

## More generic lexicon tha is applied here

### Query
A query is an organized method of retrieving data from an information system for use or modification. In the context of databases, queries are precisely formulated requests. [1]

1. https://www.techopedia.com/definition/5736/query


### Pipeline 
Pipeline is a set of data-processing stages, where the output of the previous task is used as input for the next one. This allows for big tasks to be broken down into smaller ones and for the tasks themselves to run concurrently or sequentially.

In neural networks, a pipeline is a multi-stage process where tasks like data preprocessing, feature extraction, model training, tuning, evaluation, and deployment are performed in sequence

### Architecture of a system
[Define what is the architecture of a system with several examples, one of them related to Artificial inteligence]

### Decision algorithm 
[Define what is a decision algorithm with several examples, one of them related to Artificial inteligence]

### Deployment of a system 
[Define a bit what is the deployment of a system with a several examples, one of them related to Artificial Inteligence]

## Deep learning
[Define what is deep learning and its limitations]


## Neural network
[Define Neural Network with examples and explaining the concepts bellow]

### Hyperparameter (in a neural network)

### Layer of a neural network

### Input layer

### Hidden layer

### Output layer

## Gradient of a function (and relationship with Neural Networks)
[Define what is the gradient of a function with an example and its relationship with Neural Networks]

## Dataset
[Define what is a dataset of a Deep learning network with some examples. Try to get specific]


## Large language model (LLM)
Large language models are a type of foundation models that are trained on huge quantities of data allowing them to understand and generate natural language and sound like a human alongside other types of content to perform a wide range of tasks. They can infer from context, generate coherent and contextually relevant responses, translate to languages other than English, summarize text, answer questions and even assist in creative writing or code generation tasks. LLMs played a huge role in bringing generative AI to the forefront of public interest, as well as the point where businesses are beginning to adopt 	AI across numerous business functions and use cases. LLMs are easily accessible to the public through interfaces such as Open AIs or Chat GPT. 

There are SMLs which are Small Language Models. These are essentially smaller versions of their LLM counterparts. They have significantly less parameters, typically ranging from a few million to a few billion, compared to LLMs with hundreds of billions or even trillions. This makes them more efficient since they require less computational power and memory.  

There are Convolutional Neural Networks (CNNs) they are the heart of deep learning algorithms that are designed for image recognition and processing tasks, such as object detection, segmentation, and image classification. They use three-dimensional data for image classification and object recognition tasks. 

There are audio models that are designed for speech recognition, sound analysis, and music generation. Such as WaveNet that generates speech or RNNs that models music. 


## Natural language processing model 
[Define what is it and the difference between this concept, an LLM and the concept of Natural Language Understanding]

## Machine-actionable information
Machine-actionable information is data which is formatted so that machines can read and interpret it without human action. 
To create machine-actionable information, format data in a clear, structured way like using codes, tags, or standard formats that computers can easily understand. 

For example: Words on a paper are not considered Machine-actionable information because the machine cannot work with it. The information of what pixels need to be white or black, so that they become words, is Machine-actionable information, because the machine can work with the pixel data. 

## Extra ball: Tensor
[Define what is a tensor with your words so your colleagues can more less understand it]

[some information here](https://en.wikipedia.org/wiki/Tensor_(machine_learning))


---
