# Case Study definitions (in orden of appearance) 

Before getting into the case study definitions in Depth I'm using another layer of definitions a bit more simple to later get into these concepts. 

## Latency

### Critical Path

### Machine learning dependencies

## Machine-actionable information

## Natural language understanding (NLU)

## Different types of analysis of a phrase
[Do a table of different types of analysis of a phrase and 

## Recurrent neural network (RNN)
[Build from the understanding of Neural Networks and gradient of a function from up above and explain the different concepts]

### Memory of the network

### Layer weight

### Backpropagation through time (BPTT)

### Loss function

### Vanishing gradient

## Long short-term memory (LSTM)
[Expand the the definition from the booklet with examples so everybody can understand it]

### Memory cell state
### Input gate
### Forget gate
### Output gate 

## Transformer Neural Networks (Transformer NNs)
[Build from the understanding of Neural Networks and gradient of a function from up above and explain the different concepts]


### Self-attention mechanism 
[Go in detail with this]

## Specifications of a dataset: large, accurate, classified, readable, domain specific, relevant
[For each specification write the definition and an example of a dataset that complies that specification and a dataset that doesn't comply that specification]

### Large

### Accurate

### Classified

### Readable 

### Domain specific

### Relevant

## Types of bias of datasets. 
[For each types of bias expand the definitions from the booklet and be specific in why (if applicable) are these biases unfair or inaccurate]

### Confirmation bias: 

### Historical bias: 

### Labelling bias:


### Linguistic bias:

### Sampling bias:

### Selection bias:

## Processing the data

## Preprocessing  the input data
[Explain how do you clean, select, transform y reduce the data and how you improve the quality and accuracy]

### Cleaning the data.

### Selection

### Transformation

### Reduction of data 

## Bag-of-words algorithm
[Expand the definition from the booklet with examples so everybody can understand it]

## Train a model
[Expand the definition from the booklet. Try to find how big and how much calculations do we need for training a chatbot for this context and explain the concepts related to the hardware]

### Clusters of GPU

### Tensor Processing Unit


//TO-DO


Dataset

Graphical processing unit (GPU)
Hyperparameter tuning
Large language model (LLM)
Latency
Memory cell state
Natural language processing
Discourse integration
Lexical analysis
Pragmatic analysis
Semantic analysis
Syntactical analysis (parsing)

Pre-processing
Recurrent neural network (RNN)

Synthetic data
Tensor processing unit (TPU)
Transformer neural network (transformer NN)

Weights
