# Case Study definitions (in orden of appearance) 

## Previous concepts

### Query

### Pipeline 

### Architecture of a system

### Decision algorithm 

## Neural network

### Hyperparameter (in a neural network)

### Layer of a neural network

### Input layer

### Hidden layer

### Output layer

### Gradient of a function (and relationship with Neural Networks)

## Latency

### Critical Path

### Machine learning dependencies

## Machine-actionable information

## Natural language understanding (NLU)


## Different types of analysis of a phrase (do a table)

## Recurrent neural network (RNN)

### Memory of the network

### Layer weight

### Backpropagation through time (BPTT)

### Loss function

### Vanishing gradient

## Long short-term memory (LSTM)

### Memory cell state
### Input gate
### Forget gate
### Output gate 

## Transformer Neural Networks (Transformer NNs)

### Self-attention mechanism (go a bit in detail)

## Specifications of a dataset: large, accurate, classified, readable, domain specific, relevant

## Specification of bias 

## Preprocessing  the input data



//TO-DO

Bag-of-words
Biases
  Confirmation
  Historical
  Labelling
  Linguistic
  Sampling
  Selection
Dataset
Deep learning
Graphical processing unit (GPU)
Hyperparameter tuning
Large language model (LLM)
Latency


Memory cell state
Natural language processing
Discourse integration
Lexical analysis
Pragmatic analysis
Semantic analysis
Syntactical analysis (parsing)

Pre-processing
Recurrent neural network (RNN)

Synthetic data
Tensor processing unit (TPU)
Transformer neural network (transformer NN)

Weights
